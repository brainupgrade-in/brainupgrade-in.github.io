<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <!-- Primary Meta Tags -->
    <meta name="title" content="AI Agent Design Patterns 2026: ReAct, Reflection & Planning Implementation Guide | Gheware DevOps AI">
    <meta name="description" content="Master the 3 AI agent patterns powering Claude Code, GitHub Copilot & Perplexity. Full Python implementations with LangGraph, benchmarks & production strategies.">
    <meta name="keywords" content="AI agent design patterns, ReAct pattern implementation, reflection pattern AI, planning pattern agents, LangGraph agents, AI agent frameworks 2026, Reflexion agent, Plan-and-Execute agent">
    <meta name="author" content="Rajesh Gheware">
    <meta name="robots" content="index, follow, max-snippet:-1, max-image-preview:large, max-video-preview:-1">
    <meta name="googlebot" content="index, follow">

    <!-- Canonical URL -->
    <link rel="canonical" href="https://devops.gheware.com/blog/posts/ai-agent-design-patterns-implementation-guide-2026.html">

    <!-- Favicon -->
    <link rel="icon" type="image/svg+xml" href="/favicon.svg">

    <!-- Open Graph / Facebook -->
    <meta property="og:type" content="article">
    <meta property="og:url" content="https://devops.gheware.com/blog/posts/ai-agent-design-patterns-implementation-guide-2026.html">
    <meta property="og:title" content="AI Agent Design Patterns 2026: ReAct, Reflection & Planning Implementation Guide">
    <meta property="og:description" content="Master the 3 AI agent patterns powering Claude Code, GitHub Copilot & Perplexity. Full Python implementations with LangGraph, benchmarks & production strategies.">
    <meta property="og:image" content="https://devops.gheware.com/blog/assets/images/ai-agent-design-patterns-implementation-guide-2026-hero.png">
    <meta property="og:image:width" content="1200">
    <meta property="og:image:height" content="630">
    <meta property="og:site_name" content="Gheware DevOps AI">
    <meta property="article:published_time" content="2026-01-13T10:00:00Z">
    <meta property="article:modified_time" content="2026-01-13T10:00:00Z">
    <meta property="article:author" content="Rajesh Gheware">
    <meta property="article:section" content="AI Engineering">
    <meta property="article:tag" content="AI Agents">
    <meta property="article:tag" content="LangGraph">
    <meta property="article:tag" content="Python">

    <!-- Twitter Card -->
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:site" content="@gheware_tech">
    <meta name="twitter:creator" content="@gheware_tech">
    <meta name="twitter:title" content="AI Agent Design Patterns 2026: ReAct, Reflection & Planning Implementation Guide">
    <meta name="twitter:description" content="Master the 3 AI agent patterns powering Claude Code, GitHub Copilot & Perplexity. Full Python implementations with LangGraph.">
    <meta name="twitter:image" content="https://devops.gheware.com/blog/assets/images/ai-agent-design-patterns-implementation-guide-2026-hero.png">

    <title>AI Agent Design Patterns 2026: ReAct, Reflection & Planning Implementation Guide | Gheware DevOps AI Blog</title>

    <!-- Schema.org Structured Data - BlogPosting -->
    <script type="application/ld+json">
    {
        "@context": "https://schema.org",
        "@type": "BlogPosting",
        "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "https://devops.gheware.com/blog/posts/ai-agent-design-patterns-implementation-guide-2026.html"
        },
        "headline": "AI Agent Design Patterns 2026: ReAct, Reflection & Planning Implementation Guide",
        "description": "Master the 3 AI agent patterns powering Claude Code, GitHub Copilot & Perplexity. Full Python implementations with LangGraph, benchmarks & production strategies.",
        "image": {
            "@type": "ImageObject",
            "url": "https://devops.gheware.com/blog/assets/images/ai-agent-design-patterns-implementation-guide-2026-hero.png",
            "width": 1200,
            "height": 630
        },
        "datePublished": "2026-01-13T10:00:00Z",
        "dateModified": "2026-01-13T10:00:00Z",
        "author": {
            "@type": "Person",
            "name": "Rajesh Gheware",
            "url": "https://linkedin.com/in/rajesh-gheware",
            "sameAs": [
                "https://linkedin.com/in/rajesh-gheware",
                "https://twitter.com/gheware_tech",
                "https://github.com/rajeshgheware"
            ],
            "jobTitle": "Founder & DevOps Architect",
            "worksFor": {
                "@type": "Organization",
                "name": "Gheware Technologies"
            }
        },
        "publisher": {
            "@type": "Organization",
            "name": "Gheware DevOps AI",
            "url": "https://devops.gheware.com",
            "logo": {
                "@type": "ImageObject",
                "url": "https://devops.gheware.com/favicon.svg"
            },
            "sameAs": [
                "https://youtube.com/channel/UCSHFanMgmtBK5mWXCyTCW7A",
                "https://twitter.com/gheware_tech",
                "https://linkedin.com/company/gheware-technologies"
            ]
        },
        "keywords": "AI agent design patterns, ReAct pattern, Reflection pattern, Planning pattern, LangGraph, AI agent frameworks 2026",
        "articleSection": "AI Engineering",
        "wordCount": "5800",
        "inLanguage": "en-US"
    }
    </script>

    <!-- Schema.org - BreadcrumbList -->
    <script type="application/ld+json">
    {
        "@context": "https://schema.org",
        "@type": "BreadcrumbList",
        "itemListElement": [
            {
                "@type": "ListItem",
                "position": 1,
                "name": "Home",
                "item": "https://devops.gheware.com/"
            },
            {
                "@type": "ListItem",
                "position": 2,
                "name": "Blog",
                "item": "https://devops.gheware.com/blog/"
            },
            {
                "@type": "ListItem",
                "position": 3,
                "name": "AI Agent Design Patterns Implementation Guide",
                "item": "https://devops.gheware.com/blog/posts/ai-agent-design-patterns-implementation-guide-2026.html"
            }
        ]
    }
    </script>

    <!-- Schema.org - FAQPage -->
    <script type="application/ld+json">
    {
        "@context": "https://schema.org",
        "@type": "FAQPage",
        "mainEntity": [
            {
                "@type": "Question",
                "name": "What is the ReAct pattern in AI agents?",
                "acceptedAnswer": {
                    "@type": "Answer",
                    "text": "ReAct (Reasoning and Acting) is an agent pattern that interleaves reasoning traces with action execution in a Thought-Action-Observation loop. The agent thinks about what to do, takes an action using external tools, observes the result, and uses that information for the next reasoning step. ReAct achieves 47.8% accuracy on HotpotQA multi-hop QA tasks versus 29.4% baseline."
                }
            },
            {
                "@type": "Question",
                "name": "How does the Reflection pattern improve AI agent performance?",
                "acceptedAnswer": {
                    "@type": "Answer",
                    "text": "The Reflection pattern enables agents to critique and improve their own outputs through self-evaluation. After generating an initial response, the agent assesses it for accuracy, identifies gaps, and iteratively refines the output. Reflexion agents achieve 91% pass@1 on HumanEval coding benchmarks versus GPT-4's baseline of 80%, without any fine-tuning."
                }
            },
            {
                "@type": "Question",
                "name": "When should I use Plan-and-Execute instead of ReAct?",
                "acceptedAnswer": {
                    "@type": "Answer",
                    "text": "Use Plan-and-Execute for complex multi-step tasks with dependencies, high-accuracy requirements, and long-term planning scenarios. It achieves 92% task accuracy versus 85% for ReAct but costs 2x more in API calls. ReAct is better for simple objectives requiring quick responses and real-time interactive scenarios."
                }
            },
            {
                "@type": "Question",
                "name": "What frameworks support AI agent patterns in 2026?",
                "acceptedAnswer": {
                    "@type": "Answer",
                    "text": "LangGraph (LangChain) is the leading framework with native support for ReAct, Reflection, and Plan-and-Execute patterns. OpenAI Agents SDK 0.6.x, Claude Agent SDK 1.x, CrewAI, and AutoGen also provide production-ready implementations. LangGraph offers the most flexible graph-based architecture for custom agent workflows."
                }
            },
            {
                "@type": "Question",
                "name": "How do production AI systems combine these patterns?",
                "acceptedAnswer": {
                    "@type": "Answer",
                    "text": "Real production systems combine 2-3 patterns for optimal results. Perplexity uses ReAct plus Multi-Agent architecture for search with separate retrieval, synthesis, and verification agents. Claude Code uses Reflection plus Planning with a plan mode that forces architectural thinking before execution. GitHub Copilot Chat uses ReAct with RAG for multi-file code edits."
                }
            },
            {
                "@type": "Question",
                "name": "What benchmarks prove these patterns work?",
                "acceptedAnswer": {
                    "@type": "Answer",
                    "text": "Verified benchmarks from academic papers show: ReAct achieves 47.8% on HotpotQA (vs 29.4% baseline), Reflexion reaches 91% on HumanEval (vs GPT-4's 80%), Tree of Thoughts solves 74% of Game of 24 puzzles (vs 4% for chain-of-thought), and Plan-and-Execute achieves 92% task accuracy (vs 85% for ReAct alone)."
                }
            },
            {
                "@type": "Question",
                "name": "How do I detect and prevent reasoning loops in AI agents?",
                "acceptedAnswer": {
                    "@type": "Answer",
                    "text": "Implement loop detection by tracking the last N actions in a sliding window and comparing for repeated patterns. Set maximum iteration limits (typically 10-15 iterations). Use exponential backoff with retry logic for tool failures. Monitor token usage and implement circuit breakers that fall back to simpler patterns when agents exceed thresholds."
                }
            },
            {
                "@type": "Question",
                "name": "What is the cost difference between AI agent patterns?",
                "acceptedAnswer": {
                    "@type": "Answer",
                    "text": "Direct prompting costs approximately $0.01-0.02 per query. ReAct with 3 steps costs $0.06-0.09 with 200-300% token overhead. Reflection with 2 iterations costs $0.08-0.12. Plan-and-Execute costs $0.12-0.18 with 300-400% token overhead. Combined patterns can cost $0.15-0.25 per query with 500-600% token overhead."
                }
            },
            {
                "@type": "Question",
                "name": "Which pattern should I start with for my first AI agent?",
                "acceptedAnswer": {
                    "@type": "Answer",
                    "text": "Start with the ReAct pattern for your first AI agent. It is the most widely understood, battle-tested, and suitable for 80% of use cases. ReAct provides a good balance of capability and simplicity. Once you have ReAct working, add Reflection for quality-critical tasks like code generation, or Planning for complex multi-step workflows."
                }
            },
            {
                "@type": "Question",
                "name": "How do I implement memory persistence for Reflection agents?",
                "acceptedAnswer": {
                    "@type": "Answer",
                    "text": "Use a vector database like Chroma or Pinecone to store reflections with embeddings for semantic similarity search. Store metadata including the original task, success/failure status, and timestamp. Retrieve relevant reflections by similarity to the current task, filtering by outcome type. This enables agents to learn from past failures without weight updates."
                }
            }
        ]
    }
    </script>

    <!-- Preconnect to external resources -->
    <link rel="preconnect" href="https://www.googletagmanager.com">

    <!-- CSS -->
    <link rel="stylesheet" href="/css/premium.css">
    <link rel="stylesheet" href="/blog/css/blog.css">

    <!-- Analytics & Template Loader -->
    <script src="/js/analytics-loader.js"></script>
    <script src="/js/template-loader.js" defer></script>
</head>
<body>
    <!-- Header Placeholder -->
    <div id="header-placeholder"></div>

    <!-- Breadcrumb Navigation -->
    <nav class="breadcrumb-nav" aria-label="Breadcrumb">
        <div class="container">
            <ol class="breadcrumb" itemscope itemtype="https://schema.org/BreadcrumbList">
                <li itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
                    <a itemprop="item" href="/"><span itemprop="name">Home</span></a>
                    <meta itemprop="position" content="1">
                </li>
                <li itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
                    <a itemprop="item" href="/blog/"><span itemprop="name">Blog</span></a>
                    <meta itemprop="position" content="2">
                </li>
                <li itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
                    <span itemprop="name">AI Agent Design Patterns Implementation Guide</span>
                    <meta itemprop="position" content="3">
                </li>
            </ol>
        </div>
    </nav>

    <!-- Main Article -->
    <article class="blog-post" itemscope itemtype="https://schema.org/BlogPosting">
        <meta itemprop="mainEntityOfPage" content="https://devops.gheware.com/blog/posts/ai-agent-design-patterns-implementation-guide-2026.html">

        <div class="container">
            <!-- Article Header -->
            <header class="post-header">
                <div class="post-category-wrapper">
                    <span class="post-category" itemprop="articleSection">AI Engineering</span>
                    <span class="reading-time">24 min read</span>
                </div>
                <h1 class="post-title" itemprop="headline">AI Agent Design Patterns 2026: ReAct, Reflection & Planning Implementation Guide</h1>
                <p class="post-subtitle" itemprop="description">Master the 3 AI agent patterns powering Claude Code, GitHub Copilot & Perplexity. Full Python implementations with LangGraph, verified benchmarks & production deployment strategies.</p>
                <div class="post-meta">
                    <div class="author-mini" itemprop="author" itemscope itemtype="https://schema.org/Person">
                        <img src="/images/rajesh.png" alt="Rajesh Gheware" class="author-avatar-small">
                        <div class="author-meta-text">
                            <span class="author-name" itemprop="name">Rajesh Gheware</span>
                            <time itemprop="datePublished" datetime="2026-01-13T10:00:00Z">January 13, 2026</time>
                        </div>
                    </div>
                    <div class="post-share">
                        <span>Share:</span>
                        <a href="https://twitter.com/intent/tweet?url=https://devops.gheware.com/blog/posts/ai-agent-design-patterns-implementation-guide-2026.html&text=AI%20Agent%20Design%20Patterns%202026%3A%20ReAct%2C%20Reflection%20%26%20Planning%20Implementation%20Guide" target="_blank" rel="noopener" aria-label="Share on Twitter">
                            <svg viewBox="0 0 24 24" width="20" height="20" fill="currentColor"><path d="M18.244 2.25h3.308l-7.227 8.26 8.502 11.24H16.17l-5.214-6.817L4.99 21.75H1.68l7.73-8.835L1.254 2.25H8.08l4.713 6.231zm-1.161 17.52h1.833L7.084 4.126H5.117z"/></svg>
                        </a>
                        <a href="https://www.linkedin.com/sharing/share-offsite/?url=https://devops.gheware.com/blog/posts/ai-agent-design-patterns-implementation-guide-2026.html" target="_blank" rel="noopener" aria-label="Share on LinkedIn">
                            <svg viewBox="0 0 24 24" width="20" height="20" fill="currentColor"><path d="M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433c-1.144 0-2.063-.926-2.063-2.065 0-1.138.92-2.063 2.063-2.063 1.14 0 2.064.925 2.064 2.063 0 1.139-.925 2.065-2.064 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z"/></svg>
                        </a>
                    </div>
                </div>
            </header>

            <!-- Hero Image -->
            <figure class="post-hero">
                <img src="/blog/assets/images/ai-agent-design-patterns-implementation-guide-2026-hero.png"
                     alt="AI Agent Design Patterns 2026: ReAct, Reflection and Planning Implementation Guide"
                     class="post-hero-image"
                     itemprop="image"
                     loading="eager"
                     width="1200"
                     height="630">
                <figcaption>The three core AI agent design patterns: ReAct for reasoning with tools, Reflection for self-improvement, and Planning for complex multi-step tasks.</figcaption>
            </figure>

            <!-- Quick Answer Box (AEO Critical) -->
            <aside class="quick-answer" style="background: linear-gradient(135deg, #1E3A5F 0%, #2563EB 100%); color: white; padding: 1.5rem; border-radius: 12px; margin: 2rem 0;">
                <strong style="font-size: 1.1rem;">Quick Answer:</strong>
                <p style="margin-top: 0.5rem; line-height: 1.6;">The three core AI agent design patterns are <strong>ReAct</strong> (reasoning + action loops with tools), <strong>Reflection</strong> (self-critique and iterative improvement), and <strong>Planning</strong> (goal decomposition before execution). ReAct is best for 80% of use cases. Add Reflection for code generation and quality-critical tasks. Use Planning for complex multi-step workflows with dependencies. Production systems like Claude Code, Perplexity, and GitHub Copilot combine 2-3 patterns for optimal results.</p>
            </aside>

            <!-- Key Takeaways (Critical for AEO) -->
            <aside class="key-takeaways">
                <h2>Key Takeaways</h2>
                <ul>
                    <li><strong>ReAct pattern</strong> achieves 47.8% accuracy on multi-hop QA (vs 29.4% baseline) by grounding reasoning in tool observations - ideal for 80% of agent use cases</li>
                    <li><strong>Reflexion self-improvement</strong> reaches 91% on HumanEval coding benchmarks, surpassing GPT-4's 80% baseline without any fine-tuning</li>
                    <li><strong>Plan-and-execute agents</strong> trade speed for accuracy: 92% task success vs 85% for ReAct, using 2x API calls</li>
                    <li><strong>Tree of Thoughts</strong> solves 74% of Game of 24 puzzles vs 4% for chain-of-thought, demonstrating planning's power for complex reasoning</li>
                    <li><strong>Production systems combine patterns:</strong> Claude Code uses Reflection + Planning, Perplexity uses ReAct + Multi-Agent architecture</li>
                </ul>
            </aside>

            <!-- Video Banner -->
            <div class="video-banner" style="background: linear-gradient(135deg, #1E3A5F 0%, #2563EB 100%); padding: 1.5rem; border-radius: 12px; margin: 2rem 0; text-align: center; border: 1px solid rgba(255,255,255,0.1);">
                <span class="video-banner-icon" style="font-size: 1.5rem; margin-bottom: 0.5rem; display: block;">ðŸŽ¬</span>
                <p class="video-banner-text" style="color: white; font-size: 1.1rem; margin: 0.5rem 0;">
                    <strong style="color: #60A5FA;">Prefer video?</strong> Watch
                    <a href="https://www.youtube.com/watch?v=ROPR-Nk3RmQ" target="_blank" rel="noopener" style="color: #FBBF24; text-decoration: none; font-weight: 600;">AI Agent Design Patterns 2026: ReAct, Reflection & Planning (Implementation Guide)</a>
                    on YouTube <span class="video-banner-duration" style="color: #94A3B8;">(8 min)</span>
                </p>
            </div>

            <!-- Table of Contents -->
            <nav class="table-of-contents" aria-label="Table of Contents">
                <h2>Table of Contents</h2>
                <ol>
                    <li><a href="#introduction">Why AI Agent Patterns Matter in 2026</a></li>
                    <li><a href="#react-pattern">ReAct Pattern: Reasoning + Acting Implementation</a></li>
                    <li><a href="#reflection-pattern">Reflection Pattern: Self-Improving Agents</a></li>
                    <li><a href="#planning-pattern">Planning Pattern: Goal-Oriented Decomposition</a></li>
                    <li><a href="#pattern-combinations">Pattern Combinations in Production</a></li>
                    <li><a href="#production-deployment">Production Deployment Guide</a></li>
                    <li><a href="#getting-started">Getting Started: Your Implementation Roadmap</a></li>
                    <li><a href="#faq">Frequently Asked Questions</a></li>
                </ol>
            </nav>

            <!-- Main Content -->
            <div class="post-content" itemprop="articleBody">

                <!-- Introduction -->
                <section id="introduction">
                    <h2>Why AI Agent Patterns Matter in 2026</h2>

                    <p>Your production AI agent just crashed mid-task. Again. The logs show it looped 47 times trying to parse a malformed API response before hitting the iteration limit. Sound familiar?</p>

                    <p>This is the reality of building AI agents without understanding the core design patterns that power every successful implementation. While GPT-4 solves only 4% of Game of 24 puzzles with standard prompting, agents using the Tree of Thoughts planning pattern achieve 74% success. The difference is not the model - it is the architecture.</p>

                    <p><strong>AI agent design patterns are reusable architectural solutions that solve common problems in autonomous AI systems.</strong> They define how agents reason about tasks, take actions, learn from mistakes, and plan multi-step workflows. The three patterns covered in this guide - ReAct, Reflection, and Planning - power every major AI coding assistant, search engine, and automation tool shipping in 2026.</p>

                    <aside class="definition" style="background: #f0f9ff; border-left: 4px solid #2496ED; padding: 1rem 1.5rem; margin: 1.5rem 0;">
                        <strong>AI Agent Design Pattern:</strong> A reusable architectural solution that defines how an AI agent reasons, acts, learns, and plans to accomplish goals autonomously. Patterns can be combined for production systems.
                    </aside>

                    <h3>What You Will Learn</h3>

                    <p>This implementation guide provides production-ready code for each pattern:</p>

                    <ul>
                        <li><strong>ReAct Pattern:</strong> Full LangChain and LangGraph implementations with tool integration</li>
                        <li><strong>Reflection Pattern:</strong> Reflexion agent with memory persistence using vector databases</li>
                        <li><strong>Planning Pattern:</strong> Plan-and-Execute with adaptive replanning</li>
                        <li><strong>Pattern Combinations:</strong> How Claude Code and Perplexity combine patterns</li>
                        <li><strong>Production Deployment:</strong> Error handling, observability, and scaling strategies</li>
                    </ul>

                    <p>All code examples are verified against January 2026 framework versions: LangChain 0.3.x, LangGraph 1.x, OpenAI Agents SDK 0.6.x, and Claude Agent SDK 1.x.</p>
                </section>

                <!-- ReAct Pattern Section -->
                <section id="react-pattern">
                    <h2>ReAct Pattern: Reasoning + Acting Implementation</h2>

                    <p><strong>ReAct is a pattern that interleaves reasoning traces with action execution, allowing the agent to think through problems step-by-step while taking actions and observing their outcomes.</strong> Introduced by Yao et al. in their 2022 paper "ReAct: Synergizing Reasoning and Acting in Language Models" (ICLR 2023), it remains the foundational pattern for tool-using AI agents.</p>

                    <h3>How ReAct Works</h3>

                    <p>Unlike pure chain-of-thought (reasoning only) or action-only approaches, ReAct creates a feedback loop:</p>

                    <ol>
                        <li><strong>Thought:</strong> Agent reasons about the current state and what action to take next</li>
                        <li><strong>Action:</strong> Agent invokes a tool (search, calculate, API call, etc.)</li>
                        <li><strong>Observation:</strong> Agent receives the result from the tool execution</li>
                        <li><strong>Repeat:</strong> Loop continues until the agent has enough information to answer</li>
                    </ol>

                    <h3>ReAct Benchmark Results (Verified from Original Paper)</h3>

                    <table style="width: 100%; border-collapse: collapse; margin: 1.5rem 0;">
                        <thead>
                            <tr style="background: #1E3A5F; color: white;">
                                <th style="padding: 12px; text-align: left;">Benchmark</th>
                                <th style="padding: 12px; text-align: center;">Baseline (Act-only)</th>
                                <th style="padding: 12px; text-align: center;">Chain-of-Thought</th>
                                <th style="padding: 12px; text-align: center;">ReAct</th>
                                <th style="padding: 12px; text-align: center;">ReAct + CoT</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td style="padding: 12px; border-bottom: 1px solid #e5e7eb;"><strong>HotpotQA</strong> (multi-hop QA)</td>
                                <td style="padding: 12px; text-align: center; border-bottom: 1px solid #e5e7eb;">29.4%</td>
                                <td style="padding: 12px; text-align: center; border-bottom: 1px solid #e5e7eb;">34.3%</td>
                                <td style="padding: 12px; text-align: center; border-bottom: 1px solid #e5e7eb;">34.3%</td>
                                <td style="padding: 12px; text-align: center; border-bottom: 1px solid #e5e7eb; background: #dcfce7;"><strong>47.8%</strong></td>
                            </tr>
                            <tr>
                                <td style="padding: 12px; border-bottom: 1px solid #e5e7eb;"><strong>Fever</strong> (fact verification)</td>
                                <td style="padding: 12px; text-align: center; border-bottom: 1px solid #e5e7eb;">56.3%</td>
                                <td style="padding: 12px; text-align: center; border-bottom: 1px solid #e5e7eb;">64.1%</td>
                                <td style="padding: 12px; text-align: center; border-bottom: 1px solid #e5e7eb; background: #dcfce7;"><strong>71.1%</strong></td>
                                <td style="padding: 12px; text-align: center; border-bottom: 1px solid #e5e7eb;">69.7%</td>
                            </tr>
                            <tr>
                                <td style="padding: 12px; border-bottom: 1px solid #e5e7eb;"><strong>ALFWorld</strong> (decision-making)</td>
                                <td style="padding: 12px; text-align: center; border-bottom: 1px solid #e5e7eb;">45%</td>
                                <td style="padding: 12px; text-align: center; border-bottom: 1px solid #e5e7eb;">-</td>
                                <td style="padding: 12px; text-align: center; border-bottom: 1px solid #e5e7eb; background: #dcfce7;"><strong>79%</strong></td>
                                <td style="padding: 12px; text-align: center; border-bottom: 1px solid #e5e7eb;">-</td>
                            </tr>
                            <tr>
                                <td style="padding: 12px;"><strong>WebShop</strong> (e-commerce)</td>
                                <td style="padding: 12px; text-align: center;">29.1%</td>
                                <td style="padding: 12px; text-align: center;">-</td>
                                <td style="padding: 12px; text-align: center; background: #dcfce7;"><strong>39.3%</strong></td>
                                <td style="padding: 12px; text-align: center;">-</td>
                            </tr>
                        </tbody>
                    </table>

                    <p><em>Source: Yao et al. (2022) "ReAct: Synergizing Reasoning and Acting in Language Models" - ICLR 2023</em></p>

                    <h3>Full Python Implementation with LangChain</h3>

                    <p>Here is a production-ready ReAct agent using LangChain's <code>create_react_agent</code>:</p>

<pre><code class="language-python">"""
ReAct Agent Implementation with LangChain
Requires: pip install langchain langchain-openai langchain-community
"""
from langchain import hub
from langchain_openai import ChatOpenAI
from langchain.agents import AgentExecutor, create_react_agent
from langchain_core.tools import tool
from langchain_core.prompts import PromptTemplate
import os

# Set up environment
os.environ["OPENAI_API_KEY"] = "your-api-key"

# Define custom tools
@tool
def search_wikipedia(query: str) -> str:
    """Search Wikipedia for information about a topic.
    Use this tool when you need factual information about people, places, events, or concepts.
    """
    from langchain_community.tools import WikipediaQueryRun
    from langchain_community.utilities import WikipediaAPIWrapper

    api_wrapper = WikipediaAPIWrapper(top_k_results=2, doc_content_chars_max=1000)
    wiki = WikipediaQueryRun(api_wrapper=api_wrapper)
    return wiki.run(query)

@tool
def calculate(expression: str) -> str:
    """Evaluate a mathematical expression.
    Use this tool for any calculations. Input should be a valid Python math expression.
    Examples: "2 + 2", "math.sqrt(16)", "15 * 7 / 3"
    """
    import math
    try:
        result = eval(expression, {"__builtins__": {}, "math": math})
        return str(result)
    except Exception as e:
        return f"Error evaluating expression: {e}"

# Initialize tools and model
tools = [search_wikipedia, calculate]
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)

# ReAct prompt template
react_prompt = PromptTemplate.from_template('''Answer the following questions as best you can. You have access to the following tools:

{tools}

Use the following format:

Question: the input question you must answer
Thought: you should always think about what to do
Action: the action to take, should be one of [{tool_names}]
Action Input: the input to the action
Observation: the result of the action
... (this Thought/Action/Action Input/Observation can repeat N times)
Thought: I now know the final answer
Final Answer: the final answer to the original input question

Begin!

Question: {input}
Thought:{agent_scratchpad}''')

# Create ReAct agent
agent = create_react_agent(llm, tools, react_prompt)

# Wrap in executor with error handling
agent_executor = AgentExecutor(
    agent=agent,
    tools=tools,
    verbose=True,           # Show reasoning trace
    max_iterations=10,      # Prevent infinite loops
    handle_parsing_errors=True,
    return_intermediate_steps=True  # For debugging
)

# Execute agent
def run_react_agent(question: str):
    """Run the ReAct agent and return structured response."""
    try:
        result = agent_executor.invoke({"input": question})
        return {
            "answer": result["output"],
            "steps": result.get("intermediate_steps", []),
            "success": True
        }
    except Exception as e:
        return {
            "answer": None,
            "error": str(e),
            "success": False
        }

# Example usage
if __name__ == "__main__":
    question = "What is the population of Paris, and what is the square root of that number?"
    result = run_react_agent(question)
    print(f"\nFinal Answer: {result['answer']}")
</code></pre>

                    <h3>ReAct with LangGraph (Full Control)</h3>

                    <p>For maximum flexibility, implement ReAct from scratch with LangGraph's state graph:</p>

<pre><code class="language-python">"""
ReAct Agent Implementation with LangGraph (from scratch)
Requires: pip install langgraph langchain-openai
"""
from typing import Annotated, Sequence, TypedDict
from langchain_core.messages import BaseMessage, ToolMessage, SystemMessage, HumanMessage
from langchain_core.tools import tool
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, END
from langgraph.graph.message import add_messages
import json

# Define agent state
class AgentState(TypedDict):
    """State maintained across the agent's reasoning loop."""
    messages: Annotated[Sequence[BaseMessage], add_messages]
    iteration_count: int

# Define tools
@tool
def search_web(query: str) -> str:
    """Search the web for current information."""
    # Replace with real search API in production
    return f"Search results for '{query}': [Relevant information here]"

@tool
def run_code(code: str) -> str:
    """Execute Python code and return the result."""
    try:
        local_vars = {}
        exec(code, {"__builtins__": __builtins__}, local_vars)
        return str(local_vars.get('result', 'Code executed successfully'))
    except Exception as e:
        return f"Error: {e}"

# Initialize model with tools
tools = [search_web, run_code]
model = ChatOpenAI(model="gpt-4o-mini", temperature=0)
model_with_tools = model.bind_tools(tools)
tools_by_name = {tool.name: tool for tool in tools}

# Define graph nodes
def call_model(state: AgentState) -> dict:
    """Call the LLM with current state."""
    system_message = SystemMessage(content="""You are a helpful AI assistant that uses tools to answer questions.
For each question:
1. Think about what information you need
2. Use available tools to gather that information
3. Synthesize the observations into a clear answer""")

    messages = [system_message] + list(state["messages"])
    response = model_with_tools.invoke(messages)

    return {
        "messages": [response],
        "iteration_count": state["iteration_count"] + 1
    }

def execute_tools(state: AgentState) -> dict:
    """Execute tool calls from the last message."""
    last_message = state["messages"][-1]
    outputs = []

    for tool_call in last_message.tool_calls:
        tool_name = tool_call["name"]
        tool_result = tools_by_name[tool_name].invoke(tool_call["args"])
        outputs.append(
            ToolMessage(
                content=tool_result if isinstance(tool_result, str) else json.dumps(tool_result),
                name=tool_name,
                tool_call_id=tool_call["id"]
            )
        )

    return {"messages": outputs}

def should_continue(state: AgentState) -> str:
    """Determine if agent should continue or stop."""
    last_message = state["messages"][-1]

    if state["iteration_count"] >= 10:
        return "end"

    if hasattr(last_message, "tool_calls") and last_message.tool_calls:
        return "continue"

    return "end"

# Build the graph
workflow = StateGraph(AgentState)
workflow.add_node("agent", call_model)
workflow.add_node("tools", execute_tools)
workflow.set_entry_point("agent")
workflow.add_conditional_edges("agent", should_continue, {"continue": "tools", "end": END})
workflow.add_edge("tools", "agent")

graph = workflow.compile()
</code></pre>

                    <h3>When to Use ReAct</h3>

                    <p><strong>Ideal for:</strong></p>
                    <ul>
                        <li>External tool integration (search, databases, APIs)</li>
                        <li>Multi-step problem solving requiring intermediate data</li>
                        <li>Research tasks with web search</li>
                        <li>Interactive debugging scenarios</li>
                        <li>Tasks where transparency of reasoning is important</li>
                    </ul>

                    <p><strong>Avoid when:</strong></p>
                    <ul>
                        <li>Simple direct questions (overhead not justified)</li>
                        <li>Latency-critical applications (&lt;500ms required)</li>
                        <li>Tasks requiring long-term planning with dependencies</li>
                        <li>High-accuracy requirements where reflection helps</li>
                    </ul>

                    <h3>Production Examples Using ReAct</h3>

                    <table style="width: 100%; border-collapse: collapse; margin: 1.5rem 0;">
                        <thead>
                            <tr style="background: #1E3A5F; color: white;">
                                <th style="padding: 12px; text-align: left;">Product</th>
                                <th style="padding: 12px; text-align: left;">How ReAct is Used</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td style="padding: 12px; border-bottom: 1px solid #e5e7eb;"><strong>GitHub Copilot Chat</strong></td>
                                <td style="padding: 12px; border-bottom: 1px solid #e5e7eb;">Agent Mode for multi-file edits with RAG + ReAct loop</td>
                            </tr>
                            <tr>
                                <td style="padding: 12px; border-bottom: 1px solid #e5e7eb;"><strong>Perplexity AI</strong></td>
                                <td style="padding: 12px; border-bottom: 1px solid #e5e7eb;">Search + reasoning + citation in "Pro Search" mode</td>
                            </tr>
                            <tr>
                                <td style="padding: 12px; border-bottom: 1px solid #e5e7eb;"><strong>Claude Code</strong></td>
                                <td style="padding: 12px; border-bottom: 1px solid #e5e7eb;">Tool use with terminal, files, LSP integration</td>
                            </tr>
                            <tr>
                                <td style="padding: 12px;"><strong>ChatGPT Plugins</strong></td>
                                <td style="padding: 12px;">Function calling loop with observation handling</td>
                            </tr>
                        </tbody>
                    </table>
                </section>

                <!-- Reflection Pattern Section -->
                <section id="reflection-pattern">
                    <h2>Reflection Pattern: Self-Improving Agents</h2>

                    <p><strong>The Reflection pattern adds a self-evaluation layer where agents critique their own outputs, checking for accuracy, verifying constraints, and identifying logical gaps.</strong> The breakthrough Reflexion paper by Shinn et al. (NeurIPS 2023) demonstrated that agents can learn through linguistic feedback, improving performance without weight updates.</p>

                    <h3>The Reflexion Architecture</h3>

                    <p>Reflexion implements a three-component system:</p>

                    <ol>
                        <li><strong>Actor:</strong> The LLM that generates solutions (attempts the task)</li>
                        <li><strong>Evaluator:</strong> Assesses the solution quality (pass/fail with feedback)</li>
                        <li><strong>Self-Reflection:</strong> Generates verbal feedback on failures, stored in memory</li>
                    </ol>

                    <p>The key insight is that reflections are stored in episodic memory and retrieved for future attempts, enabling the agent to learn from past mistakes.</p>

                    <h3>Reflection Benchmark Results</h3>

                    <table style="width: 100%; border-collapse: collapse; margin: 1.5rem 0;">
                        <thead>
                            <tr style="background: #1E3A5F; color: white;">
                                <th style="padding: 12px; text-align: left;">Benchmark</th>
                                <th style="padding: 12px; text-align: center;">GPT-4 Baseline</th>
                                <th style="padding: 12px; text-align: center;">Reflexion</th>
                                <th style="padding: 12px; text-align: center;">Improvement</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td style="padding: 12px; border-bottom: 1px solid #e5e7eb;"><strong>HumanEval</strong> (Python)</td>
                                <td style="padding: 12px; text-align: center; border-bottom: 1px solid #e5e7eb;">80.0% pass@1</td>
                                <td style="padding: 12px; text-align: center; border-bottom: 1px solid #e5e7eb; background: #dcfce7;"><strong>91.0%</strong></td>
                                <td style="padding: 12px; text-align: center; border-bottom: 1px solid #e5e7eb;">+11%</td>
                            </tr>
                            <tr>
                                <td style="padding: 12px; border-bottom: 1px solid #e5e7eb;"><strong>HumanEval</strong> (Rust)</td>
                                <td style="padding: 12px; text-align: center; border-bottom: 1px solid #e5e7eb;">40.6% pass@1</td>
                                <td style="padding: 12px; text-align: center; border-bottom: 1px solid #e5e7eb; background: #dcfce7;"><strong>55.9%</strong></td>
                                <td style="padding: 12px; text-align: center; border-bottom: 1px solid #e5e7eb;">+15.3%</td>
                            </tr>
                            <tr>
                                <td style="padding: 12px; border-bottom: 1px solid #e5e7eb;"><strong>ALFWorld</strong></td>
                                <td style="padding: 12px; text-align: center; border-bottom: 1px solid #e5e7eb;">24% (2 trials)</td>
                                <td style="padding: 12px; text-align: center; border-bottom: 1px solid #e5e7eb; background: #dcfce7;"><strong>97%</strong> (12 trials)</td>
                                <td style="padding: 12px; text-align: center; border-bottom: 1px solid #e5e7eb;">+73%</td>
                            </tr>
                            <tr>
                                <td style="padding: 12px;"><strong>HotpotQA</strong></td>
                                <td style="padding: 12px; text-align: center;">31.0%</td>
                                <td style="padding: 12px; text-align: center; background: #dcfce7;"><strong>51.0%</strong></td>
                                <td style="padding: 12px; text-align: center;">+20%</td>
                            </tr>
                        </tbody>
                    </table>

                    <p><em>Source: Shinn et al. (2023) "Reflexion: Language Agents with Verbal Reinforcement Learning" - NeurIPS 2023</em></p>

                    <h3>Full Reflexion Agent Implementation</h3>

<pre><code class="language-python">"""
Reflexion Agent Implementation with LangGraph
Based on Shinn et al. (2023) "Reflexion: Language Agents with Verbal Reinforcement Learning"
"""
from typing import TypedDict, List, Optional, Annotated
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, END
from langgraph.graph.message import add_messages

# State definition
class ReflexionState(TypedDict):
    """State for the Reflexion agent."""
    task: str
    current_solution: Optional[str]
    evaluation: Optional[str]
    reflections: List[str]  # Memory of past reflections
    attempts: int
    messages: Annotated[List[BaseMessage], add_messages]

# Initialize models (different models for different roles)
actor_model = ChatOpenAI(model="gpt-4o-mini", temperature=0.7)
evaluator_model = ChatOpenAI(model="gpt-4o-mini", temperature=0)
reflector_model = ChatOpenAI(model="gpt-4o-mini", temperature=0.3)

MAX_ATTEMPTS = 5

# Actor Node: Generate solution
def actor_node(state: ReflexionState) -> dict:
    """Generate or improve a solution based on task and past reflections."""

    reflection_context = ""
    if state["reflections"]:
        reflection_context = "\n\nPrevious attempts and learnings:\n"
        for i, reflection in enumerate(state["reflections"], 1):
            reflection_context += f"\nAttempt {i} Reflection:\n{reflection}\n"

    prompt = f"""You are an expert problem solver. Generate a solution for the following task.

Task: {state["task"]}
{reflection_context}

Based on any previous reflections, generate an improved solution.
Focus on avoiding past mistakes and incorporating lessons learned.

Provide your solution:"""

    response = actor_model.invoke([HumanMessage(content=prompt)])

    return {
        "current_solution": response.content,
        "attempts": state["attempts"] + 1,
        "messages": [AIMessage(content=f"Attempt {state['attempts'] + 1}:\n{response.content}")]
    }

# Evaluator Node: Assess solution quality
def evaluator_node(state: ReflexionState) -> dict:
    """Evaluate the current solution and determine if it passes."""

    prompt = f"""You are a strict evaluator. Assess if this solution correctly solves the task.

Task: {state["task"]}

Solution:
{state["current_solution"]}

Evaluate:
1. Is the solution correct and complete?
2. Are there any bugs, errors, or missing elements?
3. Does it fully address the task requirements?

Respond with exactly one of:
- PASS: [brief explanation]
- FAIL: [specific issues that need to be fixed]"""

    response = evaluator_model.invoke([HumanMessage(content=prompt)])

    return {
        "evaluation": response.content,
        "messages": [AIMessage(content=f"Evaluation: {response.content}")]
    }

# Self-Reflection Node: Generate improvement insights
def reflection_node(state: ReflexionState) -> dict:
    """Generate verbal reflection on why the solution failed."""

    prompt = f"""You are a thoughtful self-reflector. The solution failed evaluation.

Task: {state["task"]}

Failed Solution:
{state["current_solution"]}

Evaluation Feedback:
{state["evaluation"]}

Generate a reflection that:
1. Identifies the specific mistakes made
2. Explains WHY these mistakes occurred
3. Provides concrete strategies to avoid them in the next attempt
4. Suggests specific improvements to make

Your reflection (be specific and actionable):"""

    response = reflector_model.invoke([HumanMessage(content=prompt)])
    updated_reflections = state["reflections"] + [response.content]

    return {
        "reflections": updated_reflections,
        "messages": [AIMessage(content=f"Reflection: {response.content}")]
    }

# Routing logic
def should_continue(state: ReflexionState) -> str:
    if state["evaluation"] and state["evaluation"].startswith("PASS"):
        return "end"
    if state["attempts"] >= MAX_ATTEMPTS:
        return "end"
    return "reflect"

# Build the Reflexion graph
workflow = StateGraph(ReflexionState)
workflow.add_node("actor", actor_node)
workflow.add_node("evaluator", evaluator_node)
workflow.add_node("reflection", reflection_node)
workflow.set_entry_point("actor")
workflow.add_edge("actor", "evaluator")
workflow.add_conditional_edges("evaluator", should_continue, {"reflect": "reflection", "end": END})
workflow.add_edge("reflection", "actor")  # Loop back for retry

reflexion_graph = workflow.compile()
</code></pre>

                    <h3>Memory System for Reflection Agents</h3>

                    <p>For production systems, persist reflections in a vector database for semantic retrieval:</p>

<pre><code class="language-python">"""
Persistent Memory System for Reflexion using Chroma
"""
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import Chroma
from langchain_core.documents import Document

class ReflectionMemory:
    """Persistent memory for storing and retrieving reflections."""

    def __init__(self, persist_directory: str = "./reflexion_memory"):
        self.embeddings = OpenAIEmbeddings()
        self.vectorstore = Chroma(
            collection_name="reflections",
            embedding_function=self.embeddings,
            persist_directory=persist_directory
        )

    def store_reflection(self, task: str, reflection: str, success: bool):
        """Store a reflection with metadata."""
        doc = Document(
            page_content=reflection,
            metadata={"task": task, "success": success}
        )
        self.vectorstore.add_documents([doc])

    def retrieve_relevant_reflections(self, task: str, k: int = 3) -> list:
        """Retrieve reflections similar to the current task."""
        docs = self.vectorstore.similarity_search(task, k=k)
        return [
            {"reflection": doc.page_content, "task": doc.metadata.get("task")}
            for doc in docs
        ]
</code></pre>

                    <h3>Use Cases for Reflection Pattern</h3>

                    <table style="width: 100%; border-collapse: collapse; margin: 1.5rem 0;">
                        <thead>
                            <tr style="background: #1E3A5F; color: white;">
                                <th style="padding: 12px; text-align: left;">Use Case</th>
                                <th style="padding: 12px; text-align: left;">Why Reflection Helps</th>
                                <th style="padding: 12px; text-align: center;">Expected Improvement</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td style="padding: 12px; border-bottom: 1px solid #e5e7eb;"><strong>Code Generation</strong></td>
                                <td style="padding: 12px; border-bottom: 1px solid #e5e7eb;">Catches bugs through self-review</td>
                                <td style="padding: 12px; text-align: center; border-bottom: 1px solid #e5e7eb;">+10-15% pass@1</td>
                            </tr>
                            <tr>
                                <td style="padding: 12px; border-bottom: 1px solid #e5e7eb;"><strong>Creative Writing</strong></td>
                                <td style="padding: 12px; border-bottom: 1px solid #e5e7eb;">Iterative quality improvement</td>
                                <td style="padding: 12px; text-align: center; border-bottom: 1px solid #e5e7eb;">Better coherence</td>
                            </tr>
                            <tr>
                                <td style="padding: 12px; border-bottom: 1px solid #e5e7eb;"><strong>Complex Reasoning</strong></td>
                                <td style="padding: 12px; border-bottom: 1px solid #e5e7eb;">Validates logical chains</td>
                                <td style="padding: 12px; text-align: center; border-bottom: 1px solid #e5e7eb;">+20% accuracy</td>
                            </tr>
                            <tr>
                                <td style="padding: 12px;"><strong>Test Generation</strong></td>
                                <td style="padding: 12px;">Improves coverage through reflection</td>
                                <td style="padding: 12px; text-align: center;">65% to 85% coverage</td>
                            </tr>
                        </tbody>
                    </table>
                </section>

                <!-- Planning Pattern Section -->
                <section id="planning-pattern">
                    <h2>Planning Pattern: Goal-Oriented Decomposition</h2>

                    <p><strong>Plan-and-execute agents separate planning from execution, achieving 92% task accuracy compared to 85% for ReAct patterns.</strong> This pattern is essential for complex multi-step workflows where understanding the full task structure upfront leads to better outcomes.</p>

                    <h3>Planning Frameworks Comparison</h3>

                    <table style="width: 100%; border-collapse: collapse; margin: 1.5rem 0;">
                        <thead>
                            <tr style="background: #1E3A5F; color: white;">
                                <th style="padding: 12px; text-align: left;">Framework</th>
                                <th style="padding: 12px; text-align: left;">Architecture</th>
                                <th style="padding: 12px; text-align: left;">Key Innovation</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td style="padding: 12px; border-bottom: 1px solid #e5e7eb;"><strong>BabyAGI</strong></td>
                                <td style="padding: 12px; border-bottom: 1px solid #e5e7eb;">Task Creation > Prioritization > Execution</td>
                                <td style="padding: 12px; border-bottom: 1px solid #e5e7eb;">Three-agent task loop</td>
                            </tr>
                            <tr>
                                <td style="padding: 12px; border-bottom: 1px solid #e5e7eb;"><strong>AutoGPT</strong></td>
                                <td style="padding: 12px; border-bottom: 1px solid #e5e7eb;">Recursive goal decomposition</td>
                                <td style="padding: 12px; border-bottom: 1px solid #e5e7eb;">Self-prompted planning</td>
                            </tr>
                            <tr>
                                <td style="padding: 12px; border-bottom: 1px solid #e5e7eb;"><strong>LangGraph PlanAndExecute</strong></td>
                                <td style="padding: 12px; border-bottom: 1px solid #e5e7eb;">Planner + Executor + Replanner</td>
                                <td style="padding: 12px; border-bottom: 1px solid #e5e7eb;">Adaptive replanning</td>
                            </tr>
                            <tr>
                                <td style="padding: 12px; border-bottom: 1px solid #e5e7eb;"><strong>Tree of Thoughts</strong></td>
                                <td style="padding: 12px; border-bottom: 1px solid #e5e7eb;">Branch exploration + backtracking</td>
                                <td style="padding: 12px; border-bottom: 1px solid #e5e7eb;">74% on Game of 24</td>
                            </tr>
                            <tr>
                                <td style="padding: 12px;"><strong>ReWOO</strong></td>
                                <td style="padding: 12px;">Plan-first, execute-all</td>
                                <td style="padding: 12px;">80% token reduction</td>
                            </tr>
                        </tbody>
                    </table>

                    <h3>Tree of Thoughts Benchmark Results</h3>

                    <p>Tree of Thoughts demonstrates the power of deliberate planning:</p>

                    <table style="width: 100%; border-collapse: collapse; margin: 1.5rem 0;">
                        <thead>
                            <tr style="background: #1E3A5F; color: white;">
                                <th style="padding: 12px; text-align: left;">Task</th>
                                <th style="padding: 12px; text-align: center;">Chain-of-Thought</th>
                                <th style="padding: 12px; text-align: center;">Tree of Thoughts</th>
                                <th style="padding: 12px; text-align: center;">Improvement</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td style="padding: 12px; border-bottom: 1px solid #e5e7eb;"><strong>Game of 24</strong></td>
                                <td style="padding: 12px; text-align: center; border-bottom: 1px solid #e5e7eb;">4% success</td>
                                <td style="padding: 12px; text-align: center; border-bottom: 1px solid #e5e7eb; background: #dcfce7;"><strong>74%</strong> success</td>
                                <td style="padding: 12px; text-align: center; border-bottom: 1px solid #e5e7eb;">+70%</td>
                            </tr>
                            <tr>
                                <td style="padding: 12px; border-bottom: 1px solid #e5e7eb;"><strong>Creative Writing</strong></td>
                                <td style="padding: 12px; text-align: center; border-bottom: 1px solid #e5e7eb;">6.19 coherency</td>
                                <td style="padding: 12px; text-align: center; border-bottom: 1px solid #e5e7eb; background: #dcfce7;"><strong>7.67</strong> coherency</td>
                                <td style="padding: 12px; text-align: center; border-bottom: 1px solid #e5e7eb;">+24%</td>
                            </tr>
                            <tr>
                                <td style="padding: 12px;"><strong>Mini Crosswords</strong></td>
                                <td style="padding: 12px; text-align: center;">&lt;2% solved</td>
                                <td style="padding: 12px; text-align: center; background: #dcfce7;"><strong>20%</strong> solved</td>
                                <td style="padding: 12px; text-align: center;">+18%</td>
                            </tr>
                        </tbody>
                    </table>

                    <p><em>Source: Yao et al. (2023) "Tree of Thoughts: Deliberate Problem Solving with Large Language Models" - NeurIPS 2023</em></p>

                    <h3>Plan-and-Execute Implementation with LangGraph</h3>

<pre><code class="language-python">"""
Plan-and-Execute Agent Implementation with LangGraph
Based on Plan-and-Solve paper and BabyAGI project
"""
from typing import TypedDict, List, Optional
from langchain_core.messages import HumanMessage
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, END
from pydantic import BaseModel, Field
import json

# Pydantic models for structured output
class Task(BaseModel):
    """A single task in the plan."""
    id: int = Field(description="Unique task identifier")
    description: str = Field(description="What needs to be done")
    dependencies: List[int] = Field(default=[], description="IDs of tasks this depends on")
    status: str = Field(default="pending")
    result: Optional[str] = Field(default=None)

class Plan(BaseModel):
    """A complete plan with tasks."""
    goal: str = Field(description="The overall goal")
    tasks: List[Task] = Field(description="Ordered list of tasks")

# State definition
class PlanExecuteState(TypedDict):
    goal: str
    plan: Optional[Plan]
    current_task_idx: int
    completed_results: List[str]
    final_answer: Optional[str]

# Initialize models
planner_model = ChatOpenAI(model="gpt-4o", temperature=0)  # Strong planner
executor_model = ChatOpenAI(model="gpt-4o-mini", temperature=0)  # Efficient executor

# Planner Node
def planner_node(state: PlanExecuteState) -> dict:
    """Create a plan to achieve the goal."""

    prompt = f"""Create a detailed step-by-step plan to achieve this goal.

Goal: {state["goal"]}

Requirements:
1. Break down into discrete, actionable tasks
2. Order tasks logically (dependencies first)
3. Each task should be independently executable

Return as JSON:
{{"goal": "the goal", "tasks": [{{"id": 1, "description": "task", "dependencies": []}}]}}"""

    response = planner_model.invoke([HumanMessage(content=prompt)])

    # Parse the plan
    content = response.content
    if "```json" in content:
        content = content.split("```json")[1].split("```")[0]
    plan_data = json.loads(content)
    plan = Plan(**plan_data)

    return {"plan": plan, "current_task_idx": 0}

# Executor Node
def executor_node(state: PlanExecuteState) -> dict:
    """Execute the current task."""

    plan = state["plan"]
    task_idx = state["current_task_idx"]

    if task_idx >= len(plan.tasks):
        return {}

    current_task = plan.tasks[task_idx]

    context = ""
    if state["completed_results"]:
        context = "\n\nPrevious results:\n"
        for i, result in enumerate(state["completed_results"]):
            context += f"Task {i+1}: {result[:200]}...\n"

    prompt = f"""Execute this task:

Goal: {plan.goal}
Current Task: {current_task.description}
{context}

Provide a thorough result:"""

    response = executor_model.invoke([HumanMessage(content=prompt)])

    current_task.status = "completed"
    current_task.result = response.content
    updated_results = state["completed_results"] + [response.content]

    return {
        "plan": plan,
        "current_task_idx": task_idx + 1,
        "completed_results": updated_results
    }

# Synthesizer Node
def synthesizer_node(state: PlanExecuteState) -> dict:
    """Synthesize final answer from all task results."""

    plan = state["plan"]

    prompt = f"""Synthesize these results into a final answer:

Goal: {plan.goal}

Task Results:
{json.dumps([{"task": t.description, "result": t.result} for t in plan.tasks], indent=2)}

Final Answer:"""

    response = executor_model.invoke([HumanMessage(content=prompt)])

    return {"final_answer": response.content}

# Routing logic
def should_continue_execution(state: PlanExecuteState) -> str:
    if state["current_task_idx"] >= len(state["plan"].tasks):
        return "synthesize"
    return "execute"

# Build the graph
workflow = StateGraph(PlanExecuteState)
workflow.add_node("planner", planner_node)
workflow.add_node("executor", executor_node)
workflow.add_node("synthesizer", synthesizer_node)
workflow.set_entry_point("planner")
workflow.add_edge("planner", "executor")
workflow.add_conditional_edges("executor", should_continue_execution, {"execute": "executor", "synthesize": "synthesizer"})
workflow.add_edge("synthesizer", END)

plan_execute_graph = workflow.compile()
</code></pre>

                    <h3>ReAct vs Plan-and-Execute Comparison</h3>

                    <table style="width: 100%; border-collapse: collapse; margin: 1.5rem 0;">
                        <thead>
                            <tr style="background: #1E3A5F; color: white;">
                                <th style="padding: 12px; text-align: left;">Metric</th>
                                <th style="padding: 12px; text-align: center;">ReAct</th>
                                <th style="padding: 12px; text-align: center;">Plan-and-Execute</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td style="padding: 12px; border-bottom: 1px solid #e5e7eb;"><strong>Response Time</strong></td>
                                <td style="padding: 12px; text-align: center; border-bottom: 1px solid #e5e7eb; background: #dcfce7;">~2-5s (faster)</td>
                                <td style="padding: 12px; text-align: center; border-bottom: 1px solid #e5e7eb;">~5-15s</td>
                            </tr>
                            <tr>
                                <td style="padding: 12px; border-bottom: 1px solid #e5e7eb;"><strong>Token Usage</strong></td>
                                <td style="padding: 12px; text-align: center; border-bottom: 1px solid #e5e7eb; background: #dcfce7;">2000-3000</td>
                                <td style="padding: 12px; text-align: center; border-bottom: 1px solid #e5e7eb;">3000-4500</td>
                            </tr>
                            <tr>
                                <td style="padding: 12px; border-bottom: 1px solid #e5e7eb;"><strong>Task Accuracy</strong></td>
                                <td style="padding: 12px; text-align: center; border-bottom: 1px solid #e5e7eb;">85%</td>
                                <td style="padding: 12px; text-align: center; border-bottom: 1px solid #e5e7eb; background: #dcfce7;"><strong>92%</strong></td>
                            </tr>
                            <tr>
                                <td style="padding: 12px; border-bottom: 1px solid #e5e7eb;"><strong>API Calls</strong></td>
                                <td style="padding: 12px; text-align: center; border-bottom: 1px solid #e5e7eb; background: #dcfce7;">3-5</td>
                                <td style="padding: 12px; text-align: center; border-bottom: 1px solid #e5e7eb;">5-8</td>
                            </tr>
                            <tr>
                                <td style="padding: 12px;"><strong>Cost per Task</strong></td>
                                <td style="padding: 12px; text-align: center; background: #dcfce7;">$0.06-0.09</td>
                                <td style="padding: 12px; text-align: center;">$0.09-0.14</td>
                            </tr>
                        </tbody>
                    </table>

                    <p><strong>Choose Plan-and-Execute when:</strong> Complex multi-step tasks with dependencies, high-accuracy requirements (financial analysis), long-term planning scenarios, tasks requiring strategic decision-making.</p>

                    <p><strong>Choose ReAct when:</strong> Simple direct objectives, real-time interactive scenarios, cost-sensitive applications, quick responses needed.</p>
                </section>

                <!-- Pattern Combinations Section -->
                <section id="pattern-combinations">
                    <h2>Pattern Combinations in Production</h2>

                    <p>Modern production systems rarely use a single pattern. Here is how major AI products combine patterns for optimal results.</p>

                    <h3>Claude Code Architecture</h3>

                    <p>Claude Code combines Reflection and Planning patterns:</p>

                    <ul>
                        <li><strong>Plan Mode Check:</strong> For complex requests, forces planning first</li>
                        <li><strong>Planning Phase:</strong> Goal decomposition and task prioritization</li>
                        <li><strong>ReAct Execution:</strong> For each task - thought, action (LSP, terminal, files), observation</li>
                        <li><strong>Reflection Check:</strong> After key milestones, self-critique and approach updates</li>
                    </ul>

                    <h3>Perplexity AI Architecture (200M queries/day)</h3>

                    <p>Perplexity uses ReAct + Multi-Agent:</p>

                    <ul>
                        <li><strong>Query Analysis:</strong> Understand user intent</li>
                        <li><strong>Plan Generation:</strong> For Pro Search mode</li>
                        <li><strong>Retrieval Agent:</strong> Search stack execution</li>
                        <li><strong>Synthesis Agent:</strong> GPT-5/Claude 4.5 for answer generation</li>
                        <li><strong>Verification Agent:</strong> Citation checking and grounding</li>
                    </ul>

                    <h3>Pattern Selection Decision Tree</h3>

                    <p>Use this logic to select the right pattern combination:</p>

                    <ol>
                        <li><strong>Is the task simple and direct?</strong> YES: Use Direct Prompting (no agent needed)</li>
                        <li><strong>Does quality matter more than speed?</strong> YES: Add Reflection pattern</li>
                        <li><strong>Is the task genuinely complex with dependencies?</strong> YES: Consider Planning pattern</li>
                        <li><strong>Are multiple specialized skills needed?</strong> YES: Use Multi-Agent system</li>
                        <li><strong>Default:</strong> ReAct with appropriate tools</li>
                    </ol>

                    <h3>Combined Pattern Implementation</h3>

                    <p>Here is an adaptive agent that selects patterns based on task complexity:</p>

<pre><code class="language-python">"""
Combined Pattern Agent: Adaptive Pattern Selection
"""
from typing import TypedDict, List, Optional, Literal
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, END

class CombinedState(TypedDict):
    query: str
    complexity: Literal["simple", "medium", "complex"]
    plan: Optional[List[str]]
    current_step: int
    react_history: List[dict]
    reflections: List[str]
    final_answer: Optional[str]

# Complexity classifier
def classify_complexity(state: CombinedState) -> dict:
    model = ChatOpenAI(model="gpt-4o-mini", temperature=0)

    prompt = f"""Classify complexity of this task:

Task: {state["query"]}

Levels:
- SIMPLE: Direct answer, no tools, single step
- MEDIUM: Requires tools, 2-3 steps
- COMPLEX: Multi-step, dependencies, requires planning

Respond with one word: SIMPLE, MEDIUM, or COMPLEX"""

    response = model.invoke([{"role": "user", "content": prompt}])
    complexity = response.content.strip().upper()

    return {"complexity": complexity.lower() if complexity in ["SIMPLE", "MEDIUM", "COMPLEX"] else "medium"}

# Route based on complexity
def route_by_complexity(state: CombinedState) -> str:
    if state["complexity"] == "simple":
        return "direct"
    elif state["complexity"] == "complex":
        return "plan"
    else:
        return "react"
</code></pre>
                </section>

                <!-- Production Deployment Section -->
                <section id="production-deployment">
                    <h2>Production Deployment Guide</h2>

                    <h3>Error Handling Best Practices</h3>

<pre><code class="language-python">"""
Production-grade error handling for AI agents
"""
from tenacity import retry, stop_after_attempt, wait_exponential
import logging

logger = logging.getLogger(__name__)

class AgentError(Exception):
    """Base exception for agent errors."""
    pass

class MaxIterationsError(AgentError):
    """Agent exceeded maximum iterations."""
    pass

class ReasoningLoopError(AgentError):
    """Agent stuck in reasoning loop."""
    pass

@retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=2, max=10))
def safe_tool_call(tool, args):
    """Execute tool with retry logic."""
    try:
        return tool.invoke(args)
    except Exception as e:
        logger.warning(f"Tool {tool.name} failed: {e}")
        raise

def detect_reasoning_loop(history: list, window: int = 3) -> bool:
    """Detect if agent is stuck repeating the same actions."""
    if len(history) < window * 2:
        return False

    recent = history[-window:]
    previous = history[-window*2:-window]

    recent_actions = [h.get("action") for h in recent]
    previous_actions = [h.get("action") for h in previous]

    return recent_actions == previous_actions
</code></pre>

                    <h3>Observability Setup</h3>

<pre><code class="language-python">"""
Structured tracing for AI agents
"""
from dataclasses import dataclass, asdict
from datetime import datetime
import json

@dataclass
class AgentTrace:
    trace_id: str
    timestamp: str
    pattern: str  # "react", "reflection", "planning"
    input_query: str
    steps: list
    tools_called: list
    tokens_used: int
    latency_ms: int
    success: bool
    error: str = None

def create_trace(trace_id, pattern, query, steps, tools, tokens, latency, success, error=None):
    trace = AgentTrace(
        trace_id=trace_id,
        timestamp=datetime.utcnow().isoformat(),
        pattern=pattern,
        input_query=query,
        steps=steps,
        tools_called=tools,
        tokens_used=tokens,
        latency_ms=latency,
        success=success,
        error=error
    )
    return asdict(trace)
</code></pre>

                    <h3>Cost and Performance Comparison</h3>

                    <table style="width: 100%; border-collapse: collapse; margin: 1.5rem 0;">
                        <thead>
                            <tr style="background: #1E3A5F; color: white;">
                                <th style="padding: 12px; text-align: left;">Pattern</th>
                                <th style="padding: 12px; text-align: center;">Avg Latency</th>
                                <th style="padding: 12px; text-align: center;">Token Overhead</th>
                                <th style="padding: 12px; text-align: center;">Cost/Query</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td style="padding: 12px; border-bottom: 1px solid #e5e7eb;">Direct Prompting</td>
                                <td style="padding: 12px; text-align: center; border-bottom: 1px solid #e5e7eb;">1-2s</td>
                                <td style="padding: 12px; text-align: center; border-bottom: 1px solid #e5e7eb;">Baseline</td>
                                <td style="padding: 12px; text-align: center; border-bottom: 1px solid #e5e7eb;">$0.01-0.02</td>
                            </tr>
                            <tr>
                                <td style="padding: 12px; border-bottom: 1px solid #e5e7eb;">ReAct (3 steps)</td>
                                <td style="padding: 12px; text-align: center; border-bottom: 1px solid #e5e7eb;">5-10s</td>
                                <td style="padding: 12px; text-align: center; border-bottom: 1px solid #e5e7eb;">+200-300%</td>
                                <td style="padding: 12px; text-align: center; border-bottom: 1px solid #e5e7eb;">$0.06-0.09</td>
                            </tr>
                            <tr>
                                <td style="padding: 12px; border-bottom: 1px solid #e5e7eb;">Reflection (2 iter)</td>
                                <td style="padding: 12px; text-align: center; border-bottom: 1px solid #e5e7eb;">8-15s</td>
                                <td style="padding: 12px; text-align: center; border-bottom: 1px solid #e5e7eb;">+100-200%</td>
                                <td style="padding: 12px; text-align: center; border-bottom: 1px solid #e5e7eb;">$0.08-0.12</td>
                            </tr>
                            <tr>
                                <td style="padding: 12px; border-bottom: 1px solid #e5e7eb;">Plan-and-Execute</td>
                                <td style="padding: 12px; text-align: center; border-bottom: 1px solid #e5e7eb;">10-20s</td>
                                <td style="padding: 12px; text-align: center; border-bottom: 1px solid #e5e7eb;">+300-400%</td>
                                <td style="padding: 12px; text-align: center; border-bottom: 1px solid #e5e7eb;">$0.12-0.18</td>
                            </tr>
                            <tr>
                                <td style="padding: 12px;">Combined (all)</td>
                                <td style="padding: 12px; text-align: center;">15-30s</td>
                                <td style="padding: 12px; text-align: center;">+500-600%</td>
                                <td style="padding: 12px; text-align: center;">$0.15-0.25</td>
                            </tr>
                        </tbody>
                    </table>

                    <h3>Framework Recommendations (January 2026)</h3>

                    <table style="width: 100%; border-collapse: collapse; margin: 1.5rem 0;">
                        <thead>
                            <tr style="background: #1E3A5F; color: white;">
                                <th style="padding: 12px; text-align: left;">Use Case</th>
                                <th style="padding: 12px; text-align: left;">Recommended Framework</th>
                                <th style="padding: 12px; text-align: left;">Why</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td style="padding: 12px; border-bottom: 1px solid #e5e7eb;">General agents</td>
                                <td style="padding: 12px; border-bottom: 1px solid #e5e7eb;"><strong>LangGraph</strong></td>
                                <td style="padding: 12px; border-bottom: 1px solid #e5e7eb;">Flexible, production-ready</td>
                            </tr>
                            <tr>
                                <td style="padding: 12px; border-bottom: 1px solid #e5e7eb;">OpenAI-native</td>
                                <td style="padding: 12px; border-bottom: 1px solid #e5e7eb;"><strong>OpenAI Agents SDK</strong></td>
                                <td style="padding: 12px; border-bottom: 1px solid #e5e7eb;">Best GPT integration</td>
                            </tr>
                            <tr>
                                <td style="padding: 12px; border-bottom: 1px solid #e5e7eb;">Anthropic-native</td>
                                <td style="padding: 12px; border-bottom: 1px solid #e5e7eb;"><strong>Claude Agent SDK</strong></td>
                                <td style="padding: 12px; border-bottom: 1px solid #e5e7eb;">MCP support, tool use</td>
                            </tr>
                            <tr>
                                <td style="padding: 12px; border-bottom: 1px solid #e5e7eb;">Multi-agent</td>
                                <td style="padding: 12px; border-bottom: 1px solid #e5e7eb;"><strong>CrewAI or AutoGen</strong></td>
                                <td style="padding: 12px; border-bottom: 1px solid #e5e7eb;">Role-based collaboration</td>
                            </tr>
                            <tr>
                                <td style="padding: 12px;">Simple prototyping</td>
                                <td style="padding: 12px;"><strong>LangChain AgentExecutor</strong></td>
                                <td style="padding: 12px;">Quick start</td>
                            </tr>
                        </tbody>
                    </table>
                </section>

                <!-- Getting Started Section -->
                <section id="getting-started">
                    <h2>Getting Started: Your Implementation Roadmap</h2>

                    <h3>Step-by-Step Implementation Checklist</h3>

                    <ol>
                        <li><strong>Start with ReAct:</strong> Implement a basic ReAct agent with 2-3 tools. This handles 80% of use cases and builds foundational understanding.</li>
                        <li><strong>Add Observability:</strong> Implement structured tracing from day one. You cannot debug what you cannot observe.</li>
                        <li><strong>Implement Loop Detection:</strong> Add maximum iteration limits and action pattern detection to prevent infinite loops.</li>
                        <li><strong>Add Reflection for Quality:</strong> Once ReAct works, add a reflection step for code generation or high-stakes outputs.</li>
                        <li><strong>Implement Planning for Complexity:</strong> For multi-step workflows, add plan-and-execute with adaptive replanning.</li>
                        <li><strong>Combine Patterns:</strong> Use complexity classification to route requests to appropriate pattern combinations.</li>
                    </ol>

                    <h3>Common Pitfalls and Solutions</h3>

                    <table style="width: 100%; border-collapse: collapse; margin: 1.5rem 0;">
                        <thead>
                            <tr style="background: #1E3A5F; color: white;">
                                <th style="padding: 12px; text-align: left;">Pitfall</th>
                                <th style="padding: 12px; text-align: left;">Solution</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td style="padding: 12px; border-bottom: 1px solid #e5e7eb;">Agent loops forever</td>
                                <td style="padding: 12px; border-bottom: 1px solid #e5e7eb;">Set max_iterations, implement loop detection, add circuit breakers</td>
                            </tr>
                            <tr>
                                <td style="padding: 12px; border-bottom: 1px solid #e5e7eb;">Tool errors crash agent</td>
                                <td style="padding: 12px; border-bottom: 1px solid #e5e7eb;">Use retry with exponential backoff, handle_parsing_errors=True</td>
                            </tr>
                            <tr>
                                <td style="padding: 12px; border-bottom: 1px solid #e5e7eb;">Costs spiral out of control</td>
                                <td style="padding: 12px; border-bottom: 1px solid #e5e7eb;">Route by complexity, use smaller models for execution</td>
                            </tr>
                            <tr>
                                <td style="padding: 12px; border-bottom: 1px solid #e5e7eb;">Reflection does not improve quality</td>
                                <td style="padding: 12px; border-bottom: 1px solid #e5e7eb;">Use different models for actor/evaluator, be specific in evaluation prompts</td>
                            </tr>
                            <tr>
                                <td style="padding: 12px;">Plans are too vague</td>
                                <td style="padding: 12px;">Use stronger model for planning (GPT-4o), require specific task descriptions</td>
                            </tr>
                        </tbody>
                    </table>

                    <h3>Required Dependencies</h3>

<pre><code class="language-bash"># Core frameworks
pip install langchain langchain-openai langgraph

# Vector database for memory
pip install chromadb

# Error handling
pip install tenacity

# Optional: Alternative frameworks
pip install crewai autogen openai-agents-sdk
</code></pre>

                    <h3>Next Steps</h3>

                    <p>Ready to implement these patterns in your own projects? Here is what to do next:</p>

                    <ol>
                        <li><strong>Clone the code examples</strong> from the LangGraph tutorials: <a href="https://langchain-ai.github.io/langgraph/tutorials/" target="_blank" rel="noopener">https://langchain-ai.github.io/langgraph/tutorials/</a></li>
                        <li><strong>Read the original papers</strong> for deeper understanding of the theory</li>
                        <li><strong>Subscribe to our YouTube channel</strong> for video walkthroughs of these implementations</li>
                    </ol>
                </section>

                <!-- FAQ Section -->
                <section id="faq" class="faq-section">
                    <h2>Frequently Asked Questions</h2>

                    <div class="faq-item">
                        <h3>What is the ReAct pattern in AI agents?</h3>
                        <p>ReAct (Reasoning and Acting) is an agent pattern that interleaves reasoning traces with action execution in a Thought-Action-Observation loop. The agent thinks about what to do, takes an action using external tools, observes the result, and uses that information for the next reasoning step. ReAct achieves 47.8% accuracy on HotpotQA multi-hop QA tasks versus 29.4% baseline.</p>
                    </div>

                    <div class="faq-item">
                        <h3>How does the Reflection pattern improve AI agent performance?</h3>
                        <p>The Reflection pattern enables agents to critique and improve their own outputs through self-evaluation. After generating an initial response, the agent assesses it for accuracy, identifies gaps, and iteratively refines the output. Reflexion agents achieve 91% pass@1 on HumanEval coding benchmarks versus GPT-4's baseline of 80%, without any fine-tuning.</p>
                    </div>

                    <div class="faq-item">
                        <h3>When should I use Plan-and-Execute instead of ReAct?</h3>
                        <p>Use Plan-and-Execute for complex multi-step tasks with dependencies, high-accuracy requirements, and long-term planning scenarios. It achieves 92% task accuracy versus 85% for ReAct but costs 2x more in API calls. ReAct is better for simple objectives requiring quick responses and real-time interactive scenarios.</p>
                    </div>

                    <div class="faq-item">
                        <h3>What frameworks support AI agent patterns in 2026?</h3>
                        <p>LangGraph (LangChain) is the leading framework with native support for ReAct, Reflection, and Plan-and-Execute patterns. OpenAI Agents SDK 0.6.x, Claude Agent SDK 1.x, CrewAI, and AutoGen also provide production-ready implementations. LangGraph offers the most flexible graph-based architecture for custom agent workflows.</p>
                    </div>

                    <div class="faq-item">
                        <h3>How do production AI systems combine these patterns?</h3>
                        <p>Real production systems combine 2-3 patterns for optimal results. Perplexity uses ReAct plus Multi-Agent architecture for search with separate retrieval, synthesis, and verification agents. Claude Code uses Reflection plus Planning with a plan mode that forces architectural thinking before execution. GitHub Copilot Chat uses ReAct with RAG for multi-file code edits.</p>
                    </div>

                    <div class="faq-item">
                        <h3>What benchmarks prove these patterns work?</h3>
                        <p>Verified benchmarks from academic papers show: ReAct achieves 47.8% on HotpotQA (vs 29.4% baseline), Reflexion reaches 91% on HumanEval (vs GPT-4's 80%), Tree of Thoughts solves 74% of Game of 24 puzzles (vs 4% for chain-of-thought), and Plan-and-Execute achieves 92% task accuracy (vs 85% for ReAct alone).</p>
                    </div>

                    <div class="faq-item">
                        <h3>How do I detect and prevent reasoning loops in AI agents?</h3>
                        <p>Implement loop detection by tracking the last N actions in a sliding window and comparing for repeated patterns. Set maximum iteration limits (typically 10-15 iterations). Use exponential backoff with retry logic for tool failures. Monitor token usage and implement circuit breakers that fall back to simpler patterns when agents exceed thresholds.</p>
                    </div>

                    <div class="faq-item">
                        <h3>What is the cost difference between AI agent patterns?</h3>
                        <p>Direct prompting costs approximately $0.01-0.02 per query. ReAct with 3 steps costs $0.06-0.09 with 200-300% token overhead. Reflection with 2 iterations costs $0.08-0.12. Plan-and-Execute costs $0.12-0.18 with 300-400% token overhead. Combined patterns can cost $0.15-0.25 per query with 500-600% token overhead.</p>
                    </div>

                    <div class="faq-item">
                        <h3>Which pattern should I start with for my first AI agent?</h3>
                        <p>Start with the ReAct pattern for your first AI agent. It is the most widely understood, battle-tested, and suitable for 80% of use cases. ReAct provides a good balance of capability and simplicity. Once you have ReAct working, add Reflection for quality-critical tasks like code generation, or Planning for complex multi-step workflows.</p>
                    </div>

                    <div class="faq-item">
                        <h3>How do I implement memory persistence for Reflection agents?</h3>
                        <p>Use a vector database like Chroma or Pinecone to store reflections with embeddings for semantic similarity search. Store metadata including the original task, success/failure status, and timestamp. Retrieve relevant reflections by similarity to the current task, filtering by outcome type. This enables agents to learn from past failures without weight updates.</p>
                    </div>
                </section>

                <!-- Conclusion -->
                <section id="conclusion">
                    <h2>Conclusion</h2>

                    <p>The three AI agent design patterns covered in this guide - ReAct, Reflection, and Planning - represent the architectural foundation of every major AI coding assistant, search engine, and automation tool shipping in 2026.</p>

                    <p><strong>ReAct</strong> grounds reasoning in tool observations, achieving 47.8% accuracy on multi-hop QA versus 29.4% baseline. <strong>Reflection</strong> enables self-improvement that reaches 91% on HumanEval, surpassing GPT-4's 80%. <strong>Planning</strong> unlocks complex problem-solving, with Tree of Thoughts achieving 74% on puzzles that chain-of-thought solves only 4% of the time.</p>

                    <p>Production systems like Claude Code, Perplexity, and GitHub Copilot combine these patterns for optimal results. The key is not choosing a single pattern, but understanding when to apply each and how to combine them effectively.</p>

                    <p>Start with ReAct for your first agent. Add Reflection for quality-critical outputs. Use Planning for complex multi-step workflows. Implement observability from day one. Your production AI agents will thank you.</p>

                    <aside style="background: linear-gradient(135deg, #1E3A5F 0%, #326CE5 100%); color: white; padding: 2rem; border-radius: 12px; margin: 2rem 0; text-align: center;">
                        <h3 style="margin-top: 0; color: white;">Want Video Walkthroughs of These Patterns?</h3>
                        <p style="margin-bottom: 1.5rem;">Subscribe to Gheware DevOps AI for hands-on implementation tutorials, production deployment guides, and the latest AI engineering best practices.</p>
                        <a href="https://youtube.com/channel/UCSHFanMgmtBK5mWXCyTCW7A?sub_confirmation=1" target="_blank" rel="noopener" style="display: inline-block; background: #F97316; color: white; padding: 12px 24px; border-radius: 8px; text-decoration: none; font-weight: bold;">Subscribe Now</a>
                    </aside>
                </section>

            </div>

            <!-- Video CTA Card -->
            <div class="video-cta-card" style="display: flex; background: #F8FAFC; border: 1px solid #E2E8F0; border-radius: 12px; padding: 1.5rem; margin: 2.5rem 0; gap: 1.5rem; align-items: center;">
                <div class="video-cta-thumbnail" style="flex-shrink: 0;">
                    <a href="https://www.youtube.com/watch?v=ROPR-Nk3RmQ" target="_blank" rel="noopener" style="position: relative; display: block;">
                        <img src="https://img.youtube.com/vi/ROPR-Nk3RmQ/maxresdefault.jpg" alt="AI Agent Design Patterns 2026: ReAct, Reflection & Planning (Implementation Guide)" loading="lazy" style="width: 200px; height: 113px; border-radius: 8px; object-fit: cover;">
                        <span class="play-icon" style="position: absolute; top: 50%; left: 50%; transform: translate(-50%, -50%); background: rgba(0,0,0,0.8); color: white; font-size: 1.5rem; padding: 8px 12px; border-radius: 50%; text-decoration: none;">â–¶</span>
                    </a>
                </div>
                <div class="video-cta-content" style="flex-grow: 1;">
                    <span class="video-cta-badge" style="display: inline-block; background: #EF4444; color: white; padding: 4px 8px; border-radius: 4px; font-size: 0.75rem; font-weight: bold; margin-bottom: 0.5rem;">ðŸ“º Watch Video</span>
                    <h4 style="margin: 0.5rem 0; color: #1E293B; font-size: 1.2rem; line-height: 1.3;">AI Agent Design Patterns 2026: ReAct, Reflection & Planning Implementation Guide</h4>
                    <p style="margin: 0.5rem 0 1rem; color: #64748B; font-size: 0.9rem; line-height: 1.4;">Visual walkthrough of implementing ReAct, Reflection, and Planning patterns with Python code examples, benchmarks, and production strategies. See the patterns in action!</p>
                    <a href="https://www.youtube.com/watch?v=ROPR-Nk3RmQ" class="video-cta-button" target="_blank" rel="noopener" style="display: inline-flex; align-items: center; gap: 0.5rem; background: #DC2626; color: white; padding: 8px 16px; border-radius: 6px; text-decoration: none; font-size: 0.9rem; font-weight: 600; transition: background-color 0.2s;">
                        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" style="width: 16px; height: 16px;">
                            <path d="M19.615 3.184c-3.604-.246-11.631-.245-15.23 0-3.897.266-4.356 2.62-4.385 8.816.029 6.185.484 8.549 4.385 8.816 3.6.245 11.626.246 15.23 0 3.897-.266 4.356-2.62 4.385-8.816-.029-6.185-.484-8.549-4.385-8.816zm-10.615 12.816v-8l8 3.993-8 4.007z"/>
                        </svg>
                        Watch on YouTube
                    </a>
                </div>
            </div>

            <!-- Author Bio Placeholder -->
            <div id="author-bio-placeholder"></div>

            <!-- Related Articles -->
            <section class="related-articles">
                <h2>Related Articles</h2>
                <div class="related-grid">
                    <article class="related-card">
                        <h3><a href="/blog/posts/langgraph-vs-crewai-vs-autogen-comparison-2026.html">LangGraph vs CrewAI vs AutoGen: Complete AI Agent Framework Comparison 2026</a></h3>
                        <p>Compare the three leading multi-agent AI frameworks with production-ready code examples.</p>
                    </article>
                    <article class="related-card">
                        <h3><a href="/blog/posts/ai-agent-design-patterns-2026.html">5 AI Agent Design Patterns That Power Every Modern Application</a></h3>
                        <p>Master all five core patterns including Multi-Agent Systems and Chain-of-Thought.</p>
                    </article>
                    <article class="related-card">
                        <h3><a href="/blog/posts/langchain-complete-guide-2026.html">LangChain Complete Guide 2026: Build AI Applications from Scratch</a></h3>
                        <p>Master the LangChain framework with architecture, LCEL, chains, agents, and memory.</p>
                    </article>
                </div>
            </section>

            <!-- CTA Section -->
            <section class="post-cta">
                <h2>Ready to Build Production AI Agents?</h2>
                <p>Watch our hands-on video tutorials implementing ReAct, Reflection, and Planning patterns with LangGraph.</p>
                <a href="https://youtube.com/channel/UCSHFanMgmtBK5mWXCyTCW7A?sub_confirmation=1" class="btn-cta-primary" target="_blank" rel="noopener">
                    <span>Subscribe to Gheware DevOps AI</span>
                    <span class="btn-arrow">-></span>
                </a>
            </section>
        </div>
    </article>

    <!-- Footer Placeholder -->
    <div id="footer-placeholder"></div>
</body>
</html>
